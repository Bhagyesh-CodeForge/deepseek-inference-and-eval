Report: What Happens When the Model Is Guided to Reason Step-by-Step?
Date: June 20, 2025

The report is in accordance to Deepseek R1 7B model, similar behaviour is shown by 1.3B model which is used in coding.

1. Introduction-In this assignment, we explored how the DeepSeek-7B-Chat model responds to reasoning-based prompts under two different settings: with and without Chain-of-Thought (CoT) prompting. The goal was to observe how step-by-step guidance impacts the model’s accuracy and reasoning clarity.

2. Tasks & Prompts Used

Task Type	             Prompt (No CoT)	                                             Prompt (With CoT)
 Math	        What is (23 × 12) + 45?	Let's think step by step.         First multiply 23 by 12, then add 45.
 Logic	     If all cats are animals and some animals are mammals...	  Let's think step by step. All cats are animals...
  QA	        Who was the first person to walk on the moon?	          Let's think through this. The Apollo 11 mission...

3. Observations

a. Math:

i)Without CoT: The model struggled to perform arithmetic directly and gave incomplete output.

ii)With CoT: The model performed reasoning correctly and arrived at the right answer.

b. Logic:

i)Without CoT: Output was repetitive and confused, failing to logically evaluate the premises.

ii)With CoT: Output followed a reasoning chain but drifted into irrelevant associations (e.g., mammals → reptiles → insects).

c. QA:

i)Without CoT: Model output was hallucinated JavaScript code.

ii)With CoT: Started well (Neil Armstrong, Apollo 11) but hallucinated absurd details like “Rudolph the Red-Nosed Reindeer.”

4. Analysis

CoT prompting significantly improved logical flow and clarity in most structured tasks.

For open-ended or creative prompts, CoT increased fluency but also hallucinations.

Without CoT, the model sometimes defaulted to unrelated formatting or confused loops.

Despite being run on CPU, DeepSeek-7B was able to complete these tests successfully with short prompts.

5. Conclusion-Chain-of-Thought (CoT) prompting guides large language models like DeepSeek-7B to deliver more structured, logical, and often accurate responses. It is especially effective in tasks requiring multi-step reasoning. However, longer CoT responses in open-ended prompts may drift into hallucinations, so prompting must be designed carefully.